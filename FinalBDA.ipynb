{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset from the external csv file using the spark schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- user_total_orders: integer (nullable = true)\n",
      " |-- user_total_items: integer (nullable = true)\n",
      " |-- total_distinct_items: integer (nullable = true)\n",
      " |-- user_average_days_between_orders: double (nullable = true)\n",
      " |-- user_average_basket: double (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- order_hour_of_day: integer (nullable = true)\n",
      " |-- days_since_prior_order: integer (nullable = true)\n",
      " |-- days_since_ratio: double (nullable = true)\n",
      " |-- aisle_id: integer (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- product_orders: integer (nullable = true)\n",
      " |-- product_reorders: double (nullable = true)\n",
      " |-- product_reorder_rate: double (nullable = true)\n",
      " |-- z: integer (nullable = true)\n",
      " |-- UP_orders: integer (nullable = true)\n",
      " |-- UP_orders_ratio: double (nullable = true)\n",
      " |-- UP_last_order_id: integer (nullable = true)\n",
      " |-- UP_average_pos_in_cart: double (nullable = true)\n",
      " |-- UP_reorder_rate: double (nullable = true)\n",
      " |-- UP_orders_since_last: integer (nullable = true)\n",
      " |-- UP_delta_hour_vs_last: integer (nullable = true)\n",
      " |-- labels: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start session of spark using spark session to process the bigdata in parallel instead of python pandas\n",
    "# print the dataschema of the dataset\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ml-bank').getOrCreate()\n",
    "df = spark.read.csv('sampled.csv', header = True, inferSchema = True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <td>1.187899e+06</td>\n",
       "      <td>1.187899e+06</td>\n",
       "      <td>1.187899e+06</td>\n",
       "      <td>1.187899e+06</td>\n",
       "      <td>1.187899e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <td>1.712200e+04</td>\n",
       "      <td>1.960000e+02</td>\n",
       "      <td>2.640500e+04</td>\n",
       "      <td>4.614900e+04</td>\n",
       "      <td>1.408400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_total_orders</th>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_total_items</th>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>5.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_distinct_items</th>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_average_days_between_orders</th>\n",
       "      <td>1.727273e+01</td>\n",
       "      <td>1.727273e+01</td>\n",
       "      <td>1.727273e+01</td>\n",
       "      <td>1.727273e+01</td>\n",
       "      <td>1.727273e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_average_basket</th>\n",
       "      <td>5.363636e+00</td>\n",
       "      <td>5.363636e+00</td>\n",
       "      <td>5.363636e+00</td>\n",
       "      <td>5.363636e+00</td>\n",
       "      <td>5.363636e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_since_ratio</th>\n",
       "      <td>8.105263e-01</td>\n",
       "      <td>8.105263e-01</td>\n",
       "      <td>8.105263e-01</td>\n",
       "      <td>8.105263e-01</td>\n",
       "      <td>8.105263e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aisle_id</th>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>9.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_id</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_orders</th>\n",
       "      <td>1.388000e+04</td>\n",
       "      <td>3.579100e+04</td>\n",
       "      <td>1.214000e+03</td>\n",
       "      <td>8.558000e+03</td>\n",
       "      <td>1.593500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_reorders</th>\n",
       "      <td>9.377000e+03</td>\n",
       "      <td>2.779100e+04</td>\n",
       "      <td>5.360000e+02</td>\n",
       "      <td>6.953000e+03</td>\n",
       "      <td>1.292300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_reorder_rate</th>\n",
       "      <td>6.755764e-01</td>\n",
       "      <td>7.764801e-01</td>\n",
       "      <td>4.415157e-01</td>\n",
       "      <td>8.124562e-01</td>\n",
       "      <td>8.109821e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>6.712200e+04</td>\n",
       "      <td>5.019600e+04</td>\n",
       "      <td>7.640500e+04</td>\n",
       "      <td>9.614900e+04</td>\n",
       "      <td>6.408400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_orders</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_orders_ratio</th>\n",
       "      <td>9.090909e-02</td>\n",
       "      <td>9.090909e-01</td>\n",
       "      <td>1.818182e-01</td>\n",
       "      <td>2.727273e-01</td>\n",
       "      <td>9.090909e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_last_order_id</th>\n",
       "      <td>4.315340e+05</td>\n",
       "      <td>3.367565e+06</td>\n",
       "      <td>2.539329e+06</td>\n",
       "      <td>3.108588e+06</td>\n",
       "      <td>2.539329e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_average_pos_in_cart</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.400000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_reorder_rate</th>\n",
       "      <td>9.090909e-02</td>\n",
       "      <td>9.090909e-01</td>\n",
       "      <td>1.818182e-01</td>\n",
       "      <td>2.727273e-01</td>\n",
       "      <td>9.090909e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_orders_since_last</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_delta_hour_vs_last</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0             1             2  \\\n",
       "order_id                          1.187899e+06  1.187899e+06  1.187899e+06   \n",
       "product_id                        1.712200e+04  1.960000e+02  2.640500e+04   \n",
       "user_total_orders                 1.100000e+01  1.100000e+01  1.100000e+01   \n",
       "user_total_items                  5.900000e+01  5.900000e+01  5.900000e+01   \n",
       "total_distinct_items              1.800000e+01  1.800000e+01  1.800000e+01   \n",
       "user_average_days_between_orders  1.727273e+01  1.727273e+01  1.727273e+01   \n",
       "user_average_basket               5.363636e+00  5.363636e+00  5.363636e+00   \n",
       "dow                               4.000000e+00  4.000000e+00  4.000000e+00   \n",
       "order_hour_of_day                 8.000000e+00  8.000000e+00  8.000000e+00   \n",
       "days_since_prior_order            1.400000e+01  1.400000e+01  1.400000e+01   \n",
       "days_since_ratio                  8.105263e-01  8.105263e-01  8.105263e-01   \n",
       "aisle_id                          2.400000e+01  7.700000e+01  5.400000e+01   \n",
       "department_id                     4.000000e+00  7.000000e+00  1.700000e+01   \n",
       "product_orders                    1.388000e+04  3.579100e+04  1.214000e+03   \n",
       "product_reorders                  9.377000e+03  2.779100e+04  5.360000e+02   \n",
       "product_reorder_rate              6.755764e-01  7.764801e-01  4.415157e-01   \n",
       "z                                 6.712200e+04  5.019600e+04  7.640500e+04   \n",
       "UP_orders                         1.000000e+00  1.000000e+01  2.000000e+00   \n",
       "UP_orders_ratio                   9.090909e-02  9.090909e-01  1.818182e-01   \n",
       "UP_last_order_id                  4.315340e+05  3.367565e+06  2.539329e+06   \n",
       "UP_average_pos_in_cart            6.000000e+00  1.400000e+00  5.000000e+00   \n",
       "UP_reorder_rate                   9.090909e-02  9.090909e-01  1.818182e-01   \n",
       "UP_orders_since_last              6.000000e+00  5.000000e+00  1.000000e+01   \n",
       "UP_delta_hour_vs_last             7.000000e+00  1.000000e+00  0.000000e+00   \n",
       "labels                            0.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                                             3             4  \n",
       "order_id                          1.187899e+06  1.187899e+06  \n",
       "product_id                        4.614900e+04  1.408400e+04  \n",
       "user_total_orders                 1.100000e+01  1.100000e+01  \n",
       "user_total_items                  5.900000e+01  5.900000e+01  \n",
       "total_distinct_items              1.800000e+01  1.800000e+01  \n",
       "user_average_days_between_orders  1.727273e+01  1.727273e+01  \n",
       "user_average_basket               5.363636e+00  5.363636e+00  \n",
       "dow                               4.000000e+00  4.000000e+00  \n",
       "order_hour_of_day                 8.000000e+00  8.000000e+00  \n",
       "days_since_prior_order            1.400000e+01  1.400000e+01  \n",
       "days_since_ratio                  8.105263e-01  8.105263e-01  \n",
       "aisle_id                          7.700000e+01  9.100000e+01  \n",
       "department_id                     7.000000e+00  1.600000e+01  \n",
       "product_orders                    8.558000e+03  1.593500e+04  \n",
       "product_reorders                  6.953000e+03  1.292300e+04  \n",
       "product_reorder_rate              8.124562e-01  8.109821e-01  \n",
       "z                                 9.614900e+04  6.408400e+04  \n",
       "UP_orders                         3.000000e+00  1.000000e+00  \n",
       "UP_orders_ratio                   2.727273e-01  9.090909e-02  \n",
       "UP_last_order_id                  3.108588e+06  2.539329e+06  \n",
       "UP_average_pos_in_cart            3.000000e+00  2.000000e+00  \n",
       "UP_reorder_rate                   2.727273e-01  9.090909e-02  \n",
       "UP_orders_since_last              3.000000e+00  1.000000e+01  \n",
       "UP_delta_hour_vs_last             6.000000e+00  0.000000e+00  \n",
       "labels                            1.000000e+00  0.000000e+00  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test the data exported using the spark is valid with pandas and describtion of the data set \n",
    "## for better understanding\n",
    "import pandas as pd\n",
    "pd.DataFrame(df.take(5), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set summary using the mean maximum mininum and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <td>200000</td>\n",
       "      <td>1713884.290375</td>\n",
       "      <td>978079.994815277</td>\n",
       "      <td>988</td>\n",
       "      <td>3419642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <td>200000</td>\n",
       "      <td>25497.863965</td>\n",
       "      <td>14207.50981904984</td>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_total_orders</th>\n",
       "      <td>200000</td>\n",
       "      <td>25.87698</td>\n",
       "      <td>22.208253018013558</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_total_items</th>\n",
       "      <td>200000</td>\n",
       "      <td>295.68659</td>\n",
       "      <td>296.05106676947287</td>\n",
       "      <td>3</td>\n",
       "      <td>2343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_distinct_items</th>\n",
       "      <td>200000</td>\n",
       "      <td>109.60159</td>\n",
       "      <td>74.66360547644189</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>200000</td>\n",
       "      <td>2.800755</td>\n",
       "      <td>2.171662959709692</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <td>200000</td>\n",
       "      <td>13.41037</td>\n",
       "      <td>4.174296777526455</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <td>200000</td>\n",
       "      <td>14.462315</td>\n",
       "      <td>10.230197609307995</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aisle_id</th>\n",
       "      <td>200000</td>\n",
       "      <td>70.982795</td>\n",
       "      <td>38.03233152567916</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_id</th>\n",
       "      <td>200000</td>\n",
       "      <td>10.21106</td>\n",
       "      <td>6.215649350460844</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_orders</th>\n",
       "      <td>200000</td>\n",
       "      <td>22720.04431</td>\n",
       "      <td>56200.065545820464</td>\n",
       "      <td>1</td>\n",
       "      <td>472565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>200000</td>\n",
       "      <td>1.26602985363965E8</td>\n",
       "      <td>7.248827972820422E7</td>\n",
       "      <td>50196</td>\n",
       "      <td>251949235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_orders</th>\n",
       "      <td>200000</td>\n",
       "      <td>2.42809</td>\n",
       "      <td>3.5468227826689156</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_last_order_id</th>\n",
       "      <td>200000</td>\n",
       "      <td>2069969.04594</td>\n",
       "      <td>989808.8011089945</td>\n",
       "      <td>102</td>\n",
       "      <td>3420853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_orders_since_last</th>\n",
       "      <td>200000</td>\n",
       "      <td>12.88324</td>\n",
       "      <td>15.080882078559629</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP_delta_hour_vs_last</th>\n",
       "      <td>200000</td>\n",
       "      <td>4.006695</td>\n",
       "      <td>3.1487949681622354</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.10176</td>\n",
       "      <td>0.30233319273079556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0                   1                    2  \\\n",
       "summary                  count                mean               stddev   \n",
       "order_id                200000      1713884.290375     978079.994815277   \n",
       "product_id              200000        25497.863965    14207.50981904984   \n",
       "user_total_orders       200000            25.87698   22.208253018013558   \n",
       "user_total_items        200000           295.68659   296.05106676947287   \n",
       "total_distinct_items    200000           109.60159    74.66360547644189   \n",
       "dow                     200000            2.800755    2.171662959709692   \n",
       "order_hour_of_day       200000            13.41037    4.174296777526455   \n",
       "days_since_prior_order  200000           14.462315   10.230197609307995   \n",
       "aisle_id                200000           70.982795    38.03233152567916   \n",
       "department_id           200000            10.21106    6.215649350460844   \n",
       "product_orders          200000         22720.04431   56200.065545820464   \n",
       "z                       200000  1.26602985363965E8  7.248827972820422E7   \n",
       "UP_orders               200000             2.42809   3.5468227826689156   \n",
       "UP_last_order_id        200000       2069969.04594    989808.8011089945   \n",
       "UP_orders_since_last    200000            12.88324   15.080882078559629   \n",
       "UP_delta_hour_vs_last   200000            4.006695   3.1487949681622354   \n",
       "labels                  200000             0.10176  0.30233319273079556   \n",
       "\n",
       "                            3          4  \n",
       "summary                   min        max  \n",
       "order_id                  988    3419642  \n",
       "product_id                  1      49683  \n",
       "user_total_orders           4        100  \n",
       "user_total_items            3       2343  \n",
       "total_distinct_items        1        448  \n",
       "dow                         0          6  \n",
       "order_hour_of_day           0         23  \n",
       "days_since_prior_order      0         30  \n",
       "aisle_id                    1        134  \n",
       "department_id               1         21  \n",
       "product_orders              1     472565  \n",
       "z                       50196  251949235  \n",
       "UP_orders                   1         91  \n",
       "UP_last_order_id          102    3420853  \n",
       "UP_orders_since_last        1         99  \n",
       "UP_delta_hour_vs_last       0         12  \n",
       "labels                      0          1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = [t[0] for t in df.dtypes if t[1] == 'int']\n",
    "df.select(numeric_features).describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the stage for preprocessing , creation of feature vector space and label from the existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stages are used to process the data in the sequential format to avoid the parallel processing \n",
    "# due to data inconsistancy. And each stages are added to the list of stages array subsequently.\n",
    "stages = []\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "# Ignoring the features which are not required to create the feature vector space\n",
    "ignore = ['order_id','labels','dow']\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[x for x in df.columns if x not in ignore],\n",
    "    outputCol='features')\n",
    "\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data to valid form to feed the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label into label indices using the StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "\n",
    "# Using string indexer to create the labels\n",
    "label_stringIdx = StringIndexer(inputCol=\"labels\", outputCol=\"label\")\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "  \n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(df)\n",
    "preppedDataDF = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_5a5323113b32, numClasses = 2, numFeatures = 22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[order_id: int, product_id: int, user_total_orders: int, user_total_items: int, total_distinct_items: int, user_average_days_between_orders: double, user_average_basket: double, dow: int, order_hour_of_day: int, days_since_prior_order: int, days_since_ratio: double, aisle_id: int, department_id: int, product_orders: int, product_reorders: double, product_reorder_rate: double, z: int, UP_orders: int, UP_orders_ratio: double, UP_last_order_id: int, UP_average_pos_in_cart: double, UP_reorder_rate: double, UP_orders_since_last: int, UP_delta_hour_vs_last: int, labels: int, features: vector, label: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ROC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit model to prepped data\n",
    "lrModel = LogisticRegression().fit(preppedDataDF)\n",
    "\n",
    "# ROC for training data\n",
    "display(lrModel, preppedDataDF, \"ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keep relevant columns\n",
    "selectedcols = [\"label\", \"features\"]\n",
    "dataset = preppedDataDF.select(selectedcols)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140102\n",
      "59898\n"
     ]
    }
   ],
   "source": [
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "# LogisticRegression.transform() will only use the 'features' column.\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8020520972333169"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Create an initial RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "# LogisticRegression.transform() will only use the 'features' column.\n",
    "predictions = rfModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7942094863657846"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create initial Decision Tree Model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n",
    "\n",
    "# Train model with Training Data\n",
    "dtModel = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numNodes =  5\n",
      "depth =  2\n"
     ]
    }
   ],
   "source": [
    "print(\"numNodes = \", dtModel.numNodes)\n",
    "print(\"depth = \", dtModel.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_436df87d7f7a) of depth 2 with 5 nodes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dtModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the Transformer.transform() method.\n",
    "predictions = dtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31958503271457467"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression      - Score 80%\n",
    "### RandomForest Classifier - Score 79%\n",
    "### DecisionTree Classifier - Score 32%\n",
    "\n",
    "### Best model is LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation for LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .addGrid(lr.maxIter, [1, 5, 10])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(trainingData)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test set to measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8011044610624181"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "evaluator.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
